# WebScraping using Python
- BeautifulSoup was used to scrape the content of the website including the lxml parser, 
- Requests was used to get the website URL, 
- Pandas was used to store the scraped data into a dataframe
- The data was stored in Json and CSV file format
- SQLAlchemy was used to store the dataframe into PostgreSQL database!
- [DataFrame stored in Database Weather](https://user-images.githubusercontent.com/5301791/137428662-06a7fbad-047e-436a-86f7-abca0dbdc8ed.png)
- [DataFrame stored in Database Weather in Schema forecasts](https://user-images.githubusercontent.com/5301791/137428668-0fe365f7-9c22-4fd1-8e0e-03f94f68d1b5.png)
- Regex was to extract specific data from the Tonaton web page
